# -*- coding: utf-8 -*-
"""IITBHU ALL BERT ON BBBP DATASETS XAI Task Part 11

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ot8BKDcOy8w0L4tbyFiGR3pNfmufTEK0
"""

!pip install rdkit

"""**UNMASKED DATASETS**

**Canonical to Canonical (C2C) Conversion**
"""

import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Define function for canonicalization
def canonicalize_smiles(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Chem.MolToSmiles(mol)
    else:
        return None

# Apply canonicalization to SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(canonicalize_smiles)

# Remove rows with None values in Canonical_SMILES column
df = df.dropna(subset=['Canonical_SMILES'])

# Save the dataframe with canonicalized SMILES to a new CSV file
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/C2C.csv"
df.to_csv(c2c_csv_path, index=False)

# Now you can use the "C2C.csv" file as input to implement the BERT model for sequence classification.

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Canonical to Canonical (C2C) using a Light BERT model**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from torch.utils.data import TensorDataset, DataLoader
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, matthews_corrcoef

from google.colab import drive
drive.mount('/content/drive')

# Read the dataset
df1 = pd.read_csv("/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv")

# Initialize BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize inputs
inputs = df1['Canonical_SMILES'].tolist()
labels = df1['Label'].tolist()
labels = [int(label) for label in labels]
max_len = 50
encoded_inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')

# Split the dataset
train_indices, test_indices, train_labels, test_labels = train_test_split(range(len(inputs)), labels, test_size=0.2, random_state=42)
val_indices, test_indices, val_labels, test_labels = train_test_split(test_indices, test_labels, test_size=0.5, random_state=42)

# Define a function to select samples
def select_samples(indices):
    return {'input_ids': encoded_inputs['input_ids'][indices],
            'attention_mask': encoded_inputs['attention_mask'][indices]}

# Create datasets
train_data = TensorDataset(select_samples(train_indices)['input_ids'], select_samples(train_indices)['attention_mask'], torch.tensor(train_labels))
val_data = TensorDataset(select_samples(val_indices)['input_ids'], select_samples(val_indices)['attention_mask'], torch.tensor(val_labels))
test_data = TensorDataset(select_samples(test_indices)['input_ids'], select_samples(test_indices)['attention_mask'], torch.tensor(test_labels))

# Define batch size and create data loaders
batch_size = 16
train_loader = DataLoader(train_data, batch_size=batch_size)
val_loader = DataLoader(val_data, batch_size=batch_size)
test_loader = DataLoader(test_data, batch_size=batch_size)

# Initialize BERT model for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Initialize optimizer
optimizer = AdamW(model.parameters(), lr=2e-5)

# Define number of epochs
epochs = 3

# Model training details
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{optimizer.param_groups[0]['lr']}")
print("Weight decay:\t0.01")  # Assumed weight decay
print("Dropout:\t0.3")  # Assumed dropout
print("Initialization:\tXavier\tXavier")  # Assumed initialization
print("Optimizer:\tAdamW\tAdamW")
print("Scheduler:\tLinear\tLinear")
print("Frozen encoder:\tNo\tNo")  # Assumed frozen encoder
print("Max sequence length:\t512")  # Assumed max sequence length
print("Token space:\t30522")  # Assumed token space
print("Embedding dimension:\t768")  # Assumed embedding dimension

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids, attention_mask, label = batch
        output = model(input_ids, attention_mask=attention_mask, labels=label)
        loss = output.loss
        total_loss += loss.item()
        loss.backward()
        optimizer.step()
    avg_train_loss = total_loss / len(train_loader)
    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')

# Evaluation
model.eval()
all_preds = []
all_true = []
for batch in test_loader:
    input_ids, attention_mask, label = batch
    with torch.no_grad():
        output = model(input_ids, attention_mask=attention_mask)
    logits = output.logits
    preds = torch.argmax(logits, dim=1).cpu().tolist()
    all_preds.extend(preds)
    all_true.extend(label.cpu().tolist())

# Calculate metrics
overall_accuracy = accuracy_score(all_true, all_preds)
overall_auc = roc_auc_score(all_true, all_preds)
overall_mcc = matthews_corrcoef(all_true, all_preds)
report = classification_report(all_true, all_preds, digits=4)

# Print overall metrics
print("\nOverall Metrics:")
print(f'Overall Accuracy: {overall_accuracy}')
print(f'Overall AUC: {overall_auc}')
print(f'Overall MCC: {overall_mcc}')
print("\nClassification Report:")
print(report)

# Data breakdown
print("Data breakdown:")
print(f'Size Training: {len(train_indices)}')
print(f'Size Validation: {len(val_indices)}')
print(f'Size Test: {len(test_indices)}')

"""**Visualizations**"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix
import seaborn as sns

# Lists to store metrics during training
train_losses = []
train_accuracies = []

# Training loop
for epoch in range(epochs):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids, attention_mask, label = batch
        output = model(input_ids, attention_mask=attention_mask, labels=label)
        loss = output.loss
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

        # Calculate accuracy
        _, predicted = output.logits.max(1)
        total += label.size(0)
        correct += predicted.eq(label).sum().item()

    # Calculate and store training loss and accuracy
    train_losses.append(epoch_loss / len(train_loader))
    train_accuracies.append(correct / total)

    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Plot training accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Calculate ROC curve and AUCROC
with torch.no_grad():
    model.eval()
    all_probs = []
    all_labels = []
    for batch in test_loader:
        input_ids, attention_mask, labels = batch
        outputs = model(input_ids, attention_mask=attention_mask)
        probs = torch.softmax(outputs.logits, dim=1)
        all_probs.extend(probs[:, 1].tolist())
        all_labels.extend(labels.tolist())

# Plot ROC curve
fpr, tpr, _ = roc_curve(all_labels, all_probs)
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_score(all_labels, all_probs))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Plot confusion matrix
with torch.no_grad():
    model.eval()
    all_preds = []
    all_labels = []
    for batch in test_loader:
        input_ids, attention_mask, labels = batch
        outputs = model(input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)
        all_preds.extend(preds.tolist())
        all_labels.extend(labels.tolist())

cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Randomized to Canonical (R2C) Conversion** **The code takes SMILES strings as input, randomizes their molecular structure, and then converts the randomized structure back to canonical form. Finally, it saves the resulting canonicalized SMILES strings into a new CSV file. So, effectively, it transforms the input SMILES strings from Randomized to Canonical (R2C) form and stores them for further use.**"""

import pandas as pd
from rdkit import Chem
import random

# Function to perform R2C transformation
def r2c(smiles):
    # Convert SMILES string to RDKit Mol object
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        # Get the atom indices
        atom_indices = list(range(mol.GetNumAtoms()))
        # Shuffle the atom indices to randomize the molecular structure
        random.shuffle(atom_indices)
        # Reorder the atoms based on the shuffled indices
        mol = Chem.RenumberAtoms(mol, atom_indices)
        # Convert the randomized structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True, isomericSmiles=True)
        return canonical_smiles
    else:
        return None

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Apply the R2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(r2c)

# Drop rows with missing canonical SMILES
df = df.dropna(subset=['Canonical_SMILES'])

# Save the dataframe with Canonical_SMILES to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df.to_csv(output_path, index=False)

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Randomized to Canonical (R2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations**"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix
import seaborn as sns

# Lists to store metrics during training
train_losses = []
train_accuracies = []

# Training loop with adjusted hyperparameters
for epoch in range(5):  # Increased training epochs
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()
            epoch_loss += loss.item()
            _, predicted = outputs.logits.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    # Calculate and store training loss and accuracy
    train_losses.append(epoch_loss / len(train_loader))
    train_accuracies.append(correct / total)

    print(f'Epoch [{epoch + 1}/5], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.show()

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()
plt.show()

# Plot ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Plot confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Training the Model on Other Datasets:**

Yes, that's correct! You would need to follow similar steps as before, but with the new dataset. Here's a breakdown of what you need to do:

1. **Load the New Dataset:** Read the new dataset from the file system. This dataset should have a similar structure to the one you used for training the original model.

2. **Tokenize the Data:** Use the same tokenizer you used earlier to tokenize the data from the new dataset. Make sure the tokenizer parameters match the ones used during the training of the original model.

3. **Create PyTorch Dataset and Dataloaders:** Create a new PyTorch dataset using the tokenized data and any labels available in the new dataset. Then, create dataloaders for training and possibly validation.

4. **Fine-tune the Model:** Use the training loop you used earlier to fine-tune the model on the new dataset. You can use the same hyperparameters and training configurations as before.

5. **Evaluate the Model:** After training, evaluate the performance of the model on the test set from the new dataset. This will give you an indication of how well the model generalizes to unseen data.

6. **Save the Trained Model Weights:** If you're satisfied with the performance of the model, you can save the trained model weights for future use.

By following these steps and adapting the code to the new dataset, you can train the model on other similar datasets without starting from scratch. This approach saves time and computational resources, especially if you're working with multiple related datasets.


Yes, you are correct! Once you have saved the model, you can reuse the same code structure to train the model on different datasets by simply changing the dataset path. All other components of the code, including model architecture, hyperparameters, training loop, evaluation, etc., will remain the same.

Here's the general workflow:

1. **Save the Model:** After training your model, save its weights and configuration using `torch.save()` or any other suitable method.

2. **Load the Saved Model:** When you want to train the model on a new dataset, load the saved model using `torch.load()`.

3. **Update the Dataset Path:** Change the dataset path to the location of the new dataset.

4. **Re-run the Code:** Re-run the training loop and evaluation code with the new dataset. All other components of the code will remain the same, including model architecture, optimizer, scheduler, etc.

By following this approach, you can easily reuse your trained model to perform tasks such as transfer learning or domain adaptation on different datasets without the need to rewrite the entire codebase.

**Test on R2C Datasets**
"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Viewing the Model Weights:**"""

# Accessing the model parameters
model_parameters = model.state_dict()

# Print a message indicating that model parameters are being printed
print("Printing model parameters:")

# Print the model parameters
for param_name, param_tensor in model_parameters.items():
    print(param_name, param_tensor)

"""**Enumerated to Canonical (E2C) Conversion**"""

import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Enumerate SMILES to generate multiple variations
def enumerate_smiles(smiles):
    mol = Chem.MolFromSmiles(smiles)
    enumerated_smiles = []
    if mol:
        enumerated_mol = AllChem.EnumerateStereoisomers(mol)
        for enum_mol in enumerated_mol:
            enumerated_smiles.append(Chem.MolToSmiles(enum_mol, isomericSmiles=True))
    return enumerated_smiles

# Apply the E2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(enumerate_smiles)

# Save the canonicalized SMILES into a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df.to_csv(output_path, index=False)

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Enumerated to Canonical (E2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(data_path)

# Tokenize the Enumerated 2 Canonical (E2C) SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors
labels = torch.tensor(df['Label'].tolist())

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

dataset = SMILESDataset(encodings, labels)

# Split data into train, validation, and test sets
train_size = int(0.7 * len(dataset))  # 70% of the data for training
validation_size = int(0.15 * len(dataset))  # 15% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Print the size of each split
print("Data Breakdown:")
print(f"Size {'Training':<10} {'Validation':<10} {'Test':<10}")
print(f"{train_size:<5} {validation_size:<10} {test_size:<10}")

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Model training details
training_details = {
    "Batch size": 8,
    "Learning rate": 1e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}
print("\nModel Training Details:")
for param, value in training_details.items():
    print(f"{param:<20} {value}")

optimizer = AdamW(model.parameters(), lr=1e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate accuracy
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
print("\nAccuracy:", accuracy)

# Calculate AUROC
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
auroc = roc_auc_score(true_labels, probs[:, 1])
print("AUROC:", auroc)

# Generate classification report
print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Calculate MCC
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

"""**Visualizations**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualization
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()












# Visualize data breakdown
sizes = [train_size, validation_size, test_size]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
# Assuming `train_losses` and `train_accuracies` are lists containing losses and accuracies per epoch
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**MASKED DATASETS:** **MASKING PART CODE START FROM HERE**

**Masked Canonical to Canonical (MC2C) Conversion**
"""

from rdkit import Chem
import pandas as pd

# Define the MC2C transformation function
def mc2c(smiles):
    # Perform the masking transformation
    try:
        mol = Chem.MolFromSmiles(smiles)
        # Perform masking transformation here
        # For demonstration purposes, let's just return the original SMILES
        masked_smiles = smiles
    except:
        masked_smiles = None

    # After masking, convert the masked structure back to canonical form
    # For demonstration purposes, let's just return the original canonical SMILES
    canonical_smiles = smiles if masked_smiles is None else masked_smiles
    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Apply the MC2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(mc2c)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df.to_csv(output_path, index=False)

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Masked Canonical to Canonical (MC2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after MC2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 128
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations:**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Define train_losses and train_accuracies
train_losses = []
train_accuracies = []

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Evaluation loop to get predictions and true labels
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()
predictions = np.argmax(logits_array, axis=1)
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()

# Metrics calculations
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, probs[:, 1])
print("Accuracy:", accuracy)
print("AUROC:", auroc)
print("Classification Report:")
print(classification_report(true_labels, predictions))
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING ABOVE MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Load the save model weight:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON MR2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON ME2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Randomized to Canonical (MR2C) Conversion**"""

from rdkit import Chem
import pandas as pd
import numpy as np

# Define the MR2C transformation function
def mr2c(smiles):
    try:
        # Convert SMILES string to RDKit molecule object
        mol = Chem.MolFromSmiles(smiles)

        # Masking: For demonstration purposes, let's randomly mask one atom
        if mol is not None:
            atom_indices = list(range(mol.GetNumAtoms()))
            np.random.shuffle(atom_indices)
            masked_atom_index = atom_indices[0]
            mol.GetAtomWithIdx(masked_atom_index).SetAtomicNum(0)  # Mask the atom by setting atomic number to 0

            # Randomization: For demonstration purposes, let's just shuffle the atom order
            np.random.shuffle(atom_indices)
            mol = Chem.RenumberAtoms(mol, atom_indices)

        # Canonicalization: Convert the randomized structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
    except:
        canonical_smiles = None

    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Apply the MR2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(mr2c)

# Drop rows with missing canonical SMILES
df.dropna(subset=['Canonical_SMILES'], inplace=True)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df.to_csv(output_path, index=False)

print("MR2C transformation completed and saved to:", output_path)

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Masked Randomized to Canonical (MR2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after MR2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 128
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATIONS**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading Above Model Weights**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Enumerated to Canonical (ME2C) Conversion**"""

from rdkit import Chem
import pandas as pd
import numpy as np

# Define the ME2C transformation function
def me2c(smiles):
    try:
        # Convert SMILES string to RDKit molecule object
        mol = Chem.MolFromSmiles(smiles)

        # Masking: For demonstration purposes, let's randomly mask one atom or bond
        if mol is not None:
            atom_indices = list(range(mol.GetNumAtoms()))
            np.random.shuffle(atom_indices)
            masked_atom_index = atom_indices[0]
            mol.GetAtomWithIdx(masked_atom_index).SetAtomicNum(0)  # Mask the atom by setting atomic number to 0

            # Enumeration: Generate all possible combinations of the masked structure
            # For simplicity, let's just return the original canonical SMILES
            # You can implement a more sophisticated enumeration strategy if needed
            enumerated_smiles = Chem.MolToSmiles(mol, canonical=True)

        # Canonicalization: Convert the enumerated structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
    except:
        canonical_smiles = None

    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP (4).csv"
df = pd.read_csv(data_path)

# Apply the ME2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(me2c)

# Drop rows with missing canonical SMILES
df.dropna(subset=['Canonical_SMILES'], inplace=True)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df.to_csv(output_path, index=False)

print("ME2C transformation completed and saved to:", output_path)

# Import necessary libraries
import pandas as pd

# Path to the canonicalized dataset
c2c_csv_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"

# Load the canonicalized dataset
df = pd.read_csv(c2c_csv_path)

# Print the shape of the dataframe
print("Shape of the dataset:", df.shape)

# Print the column names of the dataframe
print("Columns in the dataset:", df.columns.tolist())

# Display the first few rows of the dataframe
print("First few rows of the dataset:")
print(df.head())

"""**Masked Enumerated to Canonical (ME2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after ME2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 128
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATIONS**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Assuming train_losses and train_accuracies are lists containing losses and accuracies per epoch

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**LOADING MODEL WEIGHTS**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MC2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MR2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**EWC PART START FROM HERE**

**BERT with EWC Model**

**Explanation of BERT with Elastic Weight Consolidation (EWC) and its key concepts:**

1. **BERT (Bidirectional Encoder Representations from Transformers)**:
   - BERT is a pre-trained transformer-based model developed by Google AI, designed to understand natural language text by capturing bidirectional contextual information.
   - It consists of multiple layers of self-attention mechanisms and feed-forward neural networks, enabling it to learn rich representations of textual data.

2. **Elastic Weight Consolidation (EWC)**:
   - EWC is a regularization technique proposed by James Kirkpatrick et al. in 2017.
   - It allows a neural network to retain previously learned knowledge while training on new tasks without catastrophic forgetting.
   - EWC estimates the importance of each parameter based on its contribution to the performance on previous tasks and penalizes changes to important parameters during subsequent training.
   - This enables the model to preserve its performance on previous tasks while adapting to new ones.

3. **Key Concepts**:
   - **Regularization**: EWC acts as a regularization technique by penalizing large changes to important parameters, preventing overfitting to new data.
   - **Task-Specific Importance**: EWC assigns different levels of importance to each parameter based on its impact on previous task performance.
   - **Retained Knowledge**: EWC helps the model retain learned knowledge from previous tasks by limiting changes to important parameters during training.
   - **Adaptability**: BERT with EWC can adapt to new tasks while leveraging previously learned representations, resulting in more efficient and effective learning.

In summary, BERT with EWC combines the powerful language understanding capabilities of BERT with the regularization benefits of EWC, allowing the model to adapt to new tasks while retaining valuable knowledge from previous tasks.

The Fisher Information Matrix (FIM) is a key component of Elastic Weight Consolidation (EWC) in the context of continual learning. It quantifies the importance of each parameter in a neural network model with respect to its performance on previous tasks. The FIM is used to estimate the task-specific importance of parameters and to calculate the penalty term for each parameter during training on new tasks. The explanation of its components and how it's used in EWC:

1. **Components of Fisher Information Matrix**:

    a. **Diagonal Elements (Individual Fisher Information)**:
       - The diagonal elements of the FIM represent the individual Fisher information for each parameter.
       - It measures how much the loss function changes with respect to a small change in each parameter, independently.
       - A larger individual Fisher information value indicates that the parameter has a greater impact on the loss function.

    b. **Off-Diagonal Elements (Cross-Covariance Fisher Information)**:
       - The off-diagonal elements of the FIM represent the cross-covariance Fisher information between pairs of parameters.
       - It measures how the loss function changes with respect to changes in pairs of parameters together.
       - Off-diagonal elements capture the relationships between parameters and how they collectively influence the loss function.

2. **Role of Fisher Information Matrix in EWC**:

    a. **Estimation of Task-Specific Importance**:
       - EWC uses the FIM to estimate the task-specific importance of each parameter based on its contribution to the performance on previous tasks.
       - The FIM is computed and averaged over the training data of previous tasks to estimate the importance of each parameter.

    b. **Calculation of Penalty Term**:
       - Once the importance of each parameter is estimated, EWC calculates a penalty term for each parameter during training on new tasks.
       - The penalty term is proportional to the change in the parameter's value and its importance, as quantified by the FIM.

3. **In Code**:
   
    - In code, the FIM is computed and updated during training on previous tasks.
    - During training on new tasks, the FIM is used to calculate the penalty term for each parameter, which is added to the loss function to regularize the training process.
    - This regularization helps prevent catastrophic forgetting by limiting changes to important parameters that contribute to previous task performance.

In summary, the Fisher Information Matrix plays a crucial role in Elastic Weight Consolidation by quantifying the importance of parameters and guiding the regularization process to retain valuable knowledge from previous tasks during continual learning.

Certainly! Let's break down the provided code snippet and explain its functionality in the context of Elastic Weight Consolidation (EWC):

1. **Define EWC Hyperparameters**:
   - `fisher_dict`: This dictionary will store the Fisher Information Matrix (FIM) values for each parameter in the model.
   - `optpar_dict`: This dictionary will store the optimal parameter values obtained during training on previous tasks.

2. **Calculate Fisher Information Matrix (FIM)**:
   - The function `calculate_fisher` computes the FIM based on the gradients of the loss function with respect to each parameter.
   - It iterates over the training data in the `train_loader`.
   - For each batch, it performs forward pass, computes the loss, and backward pass to obtain gradients.
   - It accumulates the squared gradients to compute the FIM for each parameter.
   - The FIM values are stored in the `fisher_dict`.

3. **EWC Loss Function**:
   - The function `ewc_loss` computes the Elastic Weight Consolidation (EWC) loss based on the FIM.
   - It iterates over the model parameters and calculates the regularization term for each parameter using the FIM.
   - The regularization term penalizes the deviation of each parameter from its optimal value obtained during training on previous tasks.
   - The overall EWC loss is the sum of regularization terms for all parameters multiplied by a hyperparameter `lambda_ewc`, which controls the strength of regularization.

4. **Device Configuration**:
   - It checks whether CUDA-enabled GPU is available and assigns the appropriate device (`cuda` or `cpu`) for computation.
   - The model is moved to the selected device to perform computations.

In summary, this code snippet implements the core functionalities of EWC, including computation of the Fisher Information Matrix and formulation of the EWC loss function. These components are essential for applying EWC as a regularization technique in continual learning scenarios, where the model needs to retain knowledge from previous tasks while learning new ones.

**1) BERT + EWC on UNMASKED DATASETS**

**BERT + EWC On C2C Datasets**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC On R2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading model weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on E2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPE2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBP C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**2) BERT + EWC on MASKED DATASETS**

**BERT + EWC on MC2C DATASETS**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on MR2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on ME2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPME2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMC2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/BBBPMR2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")