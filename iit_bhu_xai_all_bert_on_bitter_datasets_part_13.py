# -*- coding: utf-8 -*-
"""IIT BHU XAI ALL BERT ON BITTER DATASETS Part 13

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W266N9s0o49K7M0xcsThp3hxJLzxpctm

**UNMASKED DATASETS**

**Canonical to Canonical (C2C) using a Light BERT model**
"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from torch.utils.data import TensorDataset, DataLoader
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, matthews_corrcoef

from google.colab import drive
drive.mount('/content/drive')

# Read the dataset
df1 = pd.read_csv("/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv")

# Initialize BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize inputs
inputs = df1['Canonical_SMILES'].tolist()
labels = df1['Label'].tolist()
labels = [int(label) for label in labels]
max_len = 50
encoded_inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')

# Split the dataset
train_indices, test_indices, train_labels, test_labels = train_test_split(range(len(inputs)), labels, test_size=0.2, random_state=42)
val_indices, test_indices, val_labels, test_labels = train_test_split(test_indices, test_labels, test_size=0.5, random_state=42)

# Define a function to select samples
def select_samples(indices):
    return {'input_ids': encoded_inputs['input_ids'][indices],
            'attention_mask': encoded_inputs['attention_mask'][indices]}

# Create datasets
train_data = TensorDataset(select_samples(train_indices)['input_ids'], select_samples(train_indices)['attention_mask'], torch.tensor(train_labels))
val_data = TensorDataset(select_samples(val_indices)['input_ids'], select_samples(val_indices)['attention_mask'], torch.tensor(val_labels))
test_data = TensorDataset(select_samples(test_indices)['input_ids'], select_samples(test_indices)['attention_mask'], torch.tensor(test_labels))

# Define batch size and create data loaders
batch_size = 16
train_loader = DataLoader(train_data, batch_size=batch_size)
val_loader = DataLoader(val_data, batch_size=batch_size)
test_loader = DataLoader(test_data, batch_size=batch_size)

# Initialize BERT model for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Initialize optimizer
optimizer = AdamW(model.parameters(), lr=2e-5)

# Define number of epochs
epochs = 3

# Model training details
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{optimizer.param_groups[0]['lr']}")
print("Weight decay:\t0.01")  # Assumed weight decay
print("Dropout:\t0.3")  # Assumed dropout
print("Initialization:\tXavier\tXavier")  # Assumed initialization
print("Optimizer:\tAdamW\tAdamW")
print("Scheduler:\tLinear\tLinear")
print("Frozen encoder:\tNo\tNo")  # Assumed frozen encoder
print("Max sequence length:\t512")  # Assumed max sequence length
print("Token space:\t30522")  # Assumed token space
print("Embedding dimension:\t768")  # Assumed embedding dimension

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids, attention_mask, label = batch
        output = model(input_ids, attention_mask=attention_mask, labels=label)
        loss = output.loss
        total_loss += loss.item()
        loss.backward()
        optimizer.step()
    avg_train_loss = total_loss / len(train_loader)
    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')

# Evaluation
model.eval()
all_preds = []
all_true = []
for batch in test_loader:
    input_ids, attention_mask, label = batch
    with torch.no_grad():
        output = model(input_ids, attention_mask=attention_mask)
    logits = output.logits
    preds = torch.argmax(logits, dim=1).cpu().tolist()
    all_preds.extend(preds)
    all_true.extend(label.cpu().tolist())

# Calculate metrics
overall_accuracy = accuracy_score(all_true, all_preds)
overall_auc = roc_auc_score(all_true, all_preds)
overall_mcc = matthews_corrcoef(all_true, all_preds)
report = classification_report(all_true, all_preds, digits=4)

# Print overall metrics
print("\nOverall Metrics:")
print(f'Overall Accuracy: {overall_accuracy}')
print(f'Overall AUC: {overall_auc}')
print(f'Overall MCC: {overall_mcc}')
print("\nClassification Report:")
print(report)

# Data breakdown
print("Data breakdown:")
print(f'Size Training: {len(train_indices)}')
print(f'Size Validation: {len(val_indices)}')
print(f'Size Test: {len(test_indices)}')

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model BERT/C2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Randomized to Canonical (R2C) Conversion**"""

import pandas as pd
from rdkit import Chem
import random

# Function to perform R2C transformation
def r2c(smiles):
    # Convert SMILES string to RDKit Mol object
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        # Get the atom indices
        atom_indices = list(range(mol.GetNumAtoms()))
        # Shuffle the atom indices to randomize the molecular structure
        random.shuffle(atom_indices)
        # Reorder the atoms based on the shuffled indices
        mol = Chem.RenumberAtoms(mol, atom_indices)
        # Convert the randomized structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True, isomericSmiles=True)
        return canonical_smiles
    else:
        return None

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/bitter.csv"
df = pd.read_csv(data_path)

# Apply the R2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(r2c)

# Drop rows with missing canonical SMILES
df = df.dropna(subset=['Canonical_SMILES'])

# Save the dataframe with Canonical_SMILES to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df.to_csv(output_path, index=False)

"""**Randomized to Canonical (R2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations**"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix
import seaborn as sns

# Lists to store metrics during training
train_losses = []
train_accuracies = []

# Training loop with adjusted hyperparameters
for epoch in range(5):  # Increased training epochs
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()
            epoch_loss += loss.item()
            _, predicted = outputs.logits.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    # Calculate and store training loss and accuracy
    train_losses.append(epoch_loss / len(train_loader))
    train_accuracies.append(correct / total)

    print(f'Epoch [{epoch + 1}/5], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.show()

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()
plt.show()

# Plot ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Plot confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Enumerated to Canonical (E2C) Conversion**"""

import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/bitter.csv"
df = pd.read_csv(data_path)

# Enumerate SMILES to generate multiple variations
def enumerate_smiles(smiles):
    mol = Chem.MolFromSmiles(smiles)
    enumerated_smiles = []
    if mol:
        enumerated_mol = AllChem.EnumerateStereoisomers(mol)
        for enum_mol in enumerated_mol:
            enumerated_smiles.append(Chem.MolToSmiles(enum_mol, isomericSmiles=True))
    return enumerated_smiles

# Apply the E2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(enumerate_smiles)

# Save the canonicalized SMILES into a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df.to_csv(output_path, index=False)

"""**Enumerated to Canonical (E2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(data_path)

# Tokenize the Enumerated 2 Canonical (E2C) SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors
labels = torch.tensor(df['Label'].tolist())

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

dataset = SMILESDataset(encodings, labels)

# Split data into train, validation, and test sets
train_size = int(0.7 * len(dataset))  # 70% of the data for training
validation_size = int(0.15 * len(dataset))  # 15% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Print the size of each split
print("Data Breakdown:")
print(f"Size {'Training':<10} {'Validation':<10} {'Test':<10}")
print(f"{train_size:<5} {validation_size:<10} {test_size:<10}")

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Model training details
training_details = {
    "Batch size": 8,
    "Learning rate": 1e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}
print("\nModel Training Details:")
for param, value in training_details.items():
    print(f"{param:<20} {value}")

optimizer = AdamW(model.parameters(), lr=1e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate accuracy
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
print("\nAccuracy:", accuracy)

# Calculate AUROC
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
auroc = roc_auc_score(true_labels, probs[:, 1])
print("AUROC:", auroc)

# Generate classification report
print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Calculate MCC
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

"""**Visualizations**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualization
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()












# Visualize data breakdown
sizes = [train_size, validation_size, test_size]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
# Assuming `train_losses` and `train_accuracies` are lists containing losses and accuracies per epoch
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading Model Weights:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**MASKED DATASETS : MASKING PART CODE START FROM HERE**

**Masked Canonical to Canonical (MC2C) Conversion**
"""

'''from rdkit import Chem
import pandas as pd

# Define the MC2C transformation function
def mc2c(smiles):
    # Perform the masking transformation
    try:
        mol = Chem.MolFromSmiles(smiles)
        # Perform masking transformation here
        # For demonstration purposes, let's just return the original SMILES
        masked_smiles = smiles
    except:
        masked_smiles = None

    # After masking, convert the masked structure back to canonical form
    # For demonstration purposes, let's just return the original canonical SMILES
    canonical_smiles = smiles if masked_smiles is None else masked_smiles
    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/bitter.csv"
df = pd.read_csv(data_path)

# Apply the MC2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(mc2c)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df.to_csv(output_path, index=False)
'''

"""**Masked Canonical to Canonical (MC2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after MC2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 32  # Reduced batch size
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
size_training = int(0.8 * len(dataset))
size_validation = int(0.1 * len(dataset))
size_test = len(dataset) - size_training - size_validation

print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, pin_memory=True)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations:**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Define train_losses and train_accuracies
train_losses = []
train_accuracies = []

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Evaluation loop to get predictions and true labels
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()
predictions = np.argmax(logits_array, axis=1)
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()

# Metrics calculations
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, probs[:, 1])
print("Accuracy:", accuracy)
print("AUROC:", auroc)
print("Classification Report:")
print(classification_report(true_labels, predictions))
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING ABOVE MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Load the save model weight:**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON MR2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
from sklearn.metrics import roc_curve, precision_recall_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON ME2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Randomized to Canonical (MR2C) Conversion**"""

'''
from rdkit import Chem
import pandas as pd
import numpy as np

# Define the MR2C transformation function
def mr2c(smiles):
    try:
        # Convert SMILES string to RDKit molecule object
        mol = Chem.MolFromSmiles(smiles)

        # Masking: For demonstration purposes, let's randomly mask one atom
        if mol is not None:
            atom_indices = list(range(mol.GetNumAtoms()))
            np.random.shuffle(atom_indices)
            masked_atom_index = atom_indices[0]
            mol.GetAtomWithIdx(masked_atom_index).SetAtomicNum(0)  # Mask the atom by setting atomic number to 0

            # Randomization: For demonstration purposes, let's just shuffle the atom order
            np.random.shuffle(atom_indices)
            mol = Chem.RenumberAtoms(mol, atom_indices)

        # Canonicalization: Convert the randomized structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
    except:
        canonical_smiles = None

    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/bitter.csv"
df = pd.read_csv(data_path)

# Apply the MR2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(mr2c)

# Drop rows with missing canonical SMILES
df.dropna(subset=['Canonical_SMILES'], inplace=True)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df.to_csv(output_path, index=False)

print("MR2C transformation completed and saved to:", output_path)

'''

"""**Masked Randomized to Canonical (MR2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
from torch.utils.data import DataLoader, random_split

# Load the dataset with canonicalized SMILES after MR2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 8
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
train_size = int(0.8 * len(dataset))  # 80% of the dataset for training
val_size = int(0.1 * len(dataset))  # 10% of the dataset for validation
test_size = len(dataset) - train_size - val_size  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", train_size)
print("Size Validation:", val_size)
print("Size Test:", test_size)

# Split data into train, validation, and test sets
train_dataset, val_test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])
val_dataset, test_dataset = random_split(val_test_dataset, [val_size, test_size])

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Define lists to store training metrics
train_losses = []
train_accuracies = []

# Training loop with validation
for epoch in range(3):
    model.train()
    train_loss = 0
    correct_predictions = 0
    total_predictions = 0

    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()
            train_loss += loss.item()

            # Calculate accuracy
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=1)
            correct_predictions += (predictions == labels).sum().item()
            total_predictions += labels.size(0)

    avg_train_loss = train_loss / len(train_loader)
    train_accuracy = correct_predictions / total_predictions

    train_losses.append(avg_train_loss)
    train_accuracies.append(train_accuracy)

    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss}, Train Accuracy: {train_accuracy}")

    # Validation
    model.eval()
    val_loss = 0
    val_logits = []
    val_labels = []
    for batch in val_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        with torch.no_grad():
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            val_logits.append(logits)
            if 'labels' in batch:
                val_labels.extend(batch['labels'].cpu().numpy())
                loss = torch.nn.CrossEntropyLoss()(logits, torch.tensor(val_labels[-len(logits):]).to(device))
                val_loss += loss.item()

    val_logits = torch.cat(val_logits).cpu().numpy()
    if labels is not None:
        val_predictions = np.argmax(val_logits, axis=1)
        val_accuracy = accuracy_score(val_labels, val_predictions)
        print(f"Validation Accuracy: {val_accuracy}")
        print(f"Validation Loss: {val_loss / len(val_loader)}")

# Test evaluation
model.eval()
test_logits = []
test_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        test_logits.append(logits)
        if 'labels' in batch:
            test_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
test_logits = torch.cat(test_logits).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    test_predictions = np.argmax(test_logits, axis=1)
    accuracy = accuracy_score(test_labels, test_predictions)
    print("Test Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(test_logits), dim=1).cpu().numpy()
    auroc = roc_auc_score(test_labels, probs[:, 1])
    print("Test AUROC:", auroc)

    print("Test Classification Report:")
    print(classification_report(test_labels, test_predictions))

    mcc = matthews_corrcoef(test_labels, test_predictions)
    print("Test MCC:", mcc)

# Visualization Code
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Data Breakdown Visualization
sizes = [train_size, val_size, test_size]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Training Loss and Accuracy Visualization
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Confusion Matrix Visualization
cm = confusion_matrix(test_labels, test_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve Visualization
fpr, tpr, _ = roc_curve(test_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Precision-Recall Curve Visualization
precision, recall, _ = precision_recall_curve(test_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**VISUALIZATIONS**

**SAVING MODEL WEIGHTS**
"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**Loading Above Model Weights**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Enumerated to Canonical (ME2C) Conversion**"""

'''
from rdkit import Chem
import pandas as pd
import numpy as np

# Define the ME2C transformation function
def me2c(smiles):
    try:
        # Convert SMILES string to RDKit molecule object
        mol = Chem.MolFromSmiles(smiles)

        # Masking: For demonstration purposes, let's randomly mask one atom or bond
        if mol is not None:
            atom_indices = list(range(mol.GetNumAtoms()))
            np.random.shuffle(atom_indices)
            masked_atom_index = atom_indices[0]
            mol.GetAtomWithIdx(masked_atom_index).SetAtomicNum(0)  # Mask the atom by setting atomic number to 0

            # Enumeration: Generate all possible combinations of the masked structure
            # For simplicity, let's just return the original canonical SMILES
            # You can implement a more sophisticated enumeration strategy if needed
            enumerated_smiles = Chem.MolToSmiles(mol, canonical=True)

        # Canonicalization: Convert the enumerated structure back to canonical form
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
    except:
        canonical_smiles = None

    return canonical_smiles

# Load the dataset with SMILES strings
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/bitter.csv"
df = pd.read_csv(data_path)

# Apply the ME2C transformation to the SMILES column
df['Canonical_SMILES'] = df['SMILES'].apply(me2c)

# Drop rows with missing canonical SMILES
df.dropna(subset=['Canonical_SMILES'], inplace=True)

# Save the transformed dataset to a new CSV file
output_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df.to_csv(output_path, index=False)

print("ME2C transformation completed and saved to:", output_path)

'''

"""**Masked Enumerated to Canonical (ME2C) BERT Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after ME2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(data_path)

# Tokenize the canonicalized SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BERT for sequence classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details
batch_size = 128
learning_rate = 5e-5
weight_decay = 0.01
dropout = 0.1
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATIONS**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Assuming train_losses and train_accuracies are lists containing losses and accuracies per epoch

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"

# Save the model weights
model.save_pretrained(save_path)

# Print confirmation message
print("Model saved successfully at:", save_path)

"""**LOADING MODEL WEIGHTS**"""

# Load the saved model weights
model = BertForSequenceClassification.from_pretrained(save_path)

# Print confirmation message
print("Model weights loaded successfully from:", save_path)

# Now you can use this model to train on other similar datasets
# Make sure to update the dataset path and hyperparameters as needed

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MC2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MR2C DATASETS**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**EWC PART START FROM HERE**

**1) BERT + EWC on UNMASKED DATASETS**

**BERT + EWC On C2C Datasets**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC On R2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading model weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on E2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**2) BERT + EWC on MASKED DATASETS**

**BERT + EWC on MC2C DATASETS**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on MR2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BERT + EWC on ME2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BERT model architecture
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# If you have additional EWC-related data, save it separately
import pickle

# Assuming fisher_dict and optpar_dict are your EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

# Load the model and tokenizer
loaded_model = BertForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BertTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BERT+EWC_Model"
model = BertForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")