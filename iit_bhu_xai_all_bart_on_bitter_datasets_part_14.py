# -*- coding: utf-8 -*-
"""IIT BHU XAI ALL BART ON BITTER DATASETS Part 14

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VGDXX5gWXDhy15Rihq5SDB17a50d7iFo

**Canonical to Canonical (C2C) using BART model**
"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW
from torch.utils.data import TensorDataset, DataLoader
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, matthews_corrcoef

from google.colab import drive
#drive.mount('/content/drive')

# Read the dataset
df1 = pd.read_csv("/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv")

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize inputs
inputs = df1['Canonical_SMILES'].tolist()
labels = df1['Label'].tolist()
labels = [int(label) for label in labels]
max_len = 50
encoded_inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')

# Split the dataset
train_indices, test_indices, train_labels, test_labels = train_test_split(range(len(inputs)), labels, test_size=0.2, random_state=42)
val_indices, test_indices, val_labels, test_labels = train_test_split(test_indices, test_labels, test_size=0.5, random_state=42)

# Define a function to select samples
def select_samples(indices):
    return {'input_ids': encoded_inputs['input_ids'][indices],
            'attention_mask': encoded_inputs['attention_mask'][indices]}

# Create datasets
train_data = TensorDataset(select_samples(train_indices)['input_ids'], select_samples(train_indices)['attention_mask'], torch.tensor(train_labels))
val_data = TensorDataset(select_samples(val_indices)['input_ids'], select_samples(val_indices)['attention_mask'], torch.tensor(val_labels))
test_data = TensorDataset(select_samples(test_indices)['input_ids'], select_samples(test_indices)['attention_mask'], torch.tensor(test_labels))

# Define batch size and create data loaders
batch_size = 16
train_loader = DataLoader(train_data, batch_size=batch_size)
val_loader = DataLoader(val_data, batch_size=batch_size)
test_loader = DataLoader(test_data, batch_size=batch_size)

# Initialize BART model for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Initialize optimizer
optimizer = AdamW(model.parameters(), lr=2e-5)

# Define number of epochs
epochs = 3

# Model training details
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{optimizer.param_groups[0]['lr']}")
print("Weight decay:\t0.01")  # Assumed weight decay
print("Dropout:\t0.3")  # Assumed dropout
print("Initialization:\tXavier\tXavier")  # Assumed initialization
print("Optimizer:\tAdamW\tAdamW")
print("Scheduler:\tLinear\tLinear")
print("Frozen encoder:\tNo\tNo")  # Assumed frozen encoder
print("Max sequence length:\t512")  # Assumed max sequence length
print("Token space:\t30522")  # Assumed token space
print("Embedding dimension:\t768")  # Assumed embedding dimension

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids, attention_mask, label = batch
        output = model(input_ids, attention_mask=attention_mask, labels=label)
        loss = output.loss
        total_loss += loss.item()
        loss.backward()
        optimizer.step()
    avg_train_loss = total_loss / len(train_loader)
    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')

# Evaluation
model.eval()
all_preds = []
all_true = []
for batch in test_loader:
    input_ids, attention_mask, label = batch
    with torch.no_grad():
        output = model(input_ids, attention_mask=attention_mask)
    logits = output.logits
    preds = torch.argmax(logits, dim=1).cpu().tolist()
    all_preds.extend(preds)
    all_true.extend(label.cpu().tolist())

# Calculate metrics
overall_accuracy = accuracy_score(all_true, all_preds)
overall_auc = roc_auc_score(all_true, all_preds)
overall_mcc = matthews_corrcoef(all_true, all_preds)
report = classification_report(all_true, all_preds, digits=4)

# Print overall metrics
print("\nOverall Metrics:")
print(f'Overall Accuracy: {overall_accuracy}')
print(f'Overall AUC: {overall_auc}')
print(f'Overall MCC: {overall_mcc}')
print("\nClassification Report:")
print(report)

# Data breakdown
print("Data breakdown:")
print(f'Size Training: {len(train_indices)}')
print(f'Size Validation: {len(val_indices)}')
print(f'Size Test: {len(test_indices)}')

"""**VISUALIZATION**"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix
import seaborn as sns

# Lists to store metrics during training
train_losses = []
train_accuracies = []

# Training loop
for epoch in range(epochs):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids, attention_mask, label = batch
        output = model(input_ids, attention_mask=attention_mask, labels=label)
        loss = output.loss
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

        # Calculate accuracy
        _, predicted = output.logits.max(1)
        total += label.size(0)
        correct += predicted.eq(label).sum().item()

    # Calculate and store training loss and accuracy
    train_losses.append(epoch_loss / len(train_loader))
    train_accuracies.append(correct / total)

    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Plot training accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Calculate ROC curve and AUCROC
with torch.no_grad():
    model.eval()
    all_probs = []
    all_labels = []
    for batch in test_loader:
        input_ids, attention_mask, labels = batch
        outputs = model(input_ids, attention_mask=attention_mask)
        probs = torch.softmax(outputs.logits, dim=1)
        all_probs.extend(probs[:, 1].tolist())
        all_labels.extend(labels.tolist())

# Plot ROC curve
fpr, tpr, _ = roc_curve(all_labels, all_probs)
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_score(all_labels, all_probs))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Plot confusion matrix
with torch.no_grad():
    model.eval()
    all_preds = []
    all_labels = []
    for batch in test_loader:
        input_ids, attention_mask, labels = batch
        outputs = model(input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)
        all_preds.extend(preds.tolist())
        all_labels.extend(labels.tolist())

cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Randomized to Canonical (R2C) BART Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the canonicalized SMILES sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BART for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train and test sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATION**"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix
import seaborn as sns

# Lists to store metrics during training
train_losses = []
train_accuracies = []

# Training loop with adjusted hyperparameters
for epoch in range(5):  # Increased training epochs
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()
            epoch_loss += loss.item()
            _, predicted = outputs.logits.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    # Calculate and store training loss and accuracy
    train_losses.append(epoch_loss / len(train_loader))
    train_accuracies.append(correct / total)

    print(f'Epoch [{epoch + 1}/5], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()
plt.show()

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_accuracies, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()
plt.show()

# Plot ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Plot confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**Loading the Model Weights:**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Enumerated to Canonical (E2C) BART Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the canonicalized SMILES sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BART for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train, validation, and test sets
train_size = int(0.7 * len(dataset))  # 70% of the data for training
validation_size = int(0.15 * len(dataset))  # 15% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualization
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()












# Visualize data breakdown
sizes = [train_size, validation_size, test_size]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
# Assuming `train_losses` and `train_accuracies` are lists containing losses and accuracies per epoch
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving the Model Weights:**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**Loading Model Weights:**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**MASKED DATASETS : MASKING PART CODE START FROM HERE**

**Masked Canonical to Canonical (MC2C) BART Model**
"""

import pandas as pd
import numpy as np
import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the canonicalized SMILES sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BART for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train, validation, and test sets
train_size = int(0.7 * len(dataset))  # 70% of the data for training
validation_size = int(0.15 * len(dataset))  # 15% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**Visualizations:**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Define train_losses and train_accuracies
train_losses = []
train_accuracies = []

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Evaluation loop to get predictions and true labels
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()
predictions = np.argmax(logits_array, axis=1)
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()

# Metrics calculations
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, probs[:, 1])
print("Accuracy:", accuracy)
print("AUROC:", auroc)
print("Classification Report:")
print(classification_report(true_labels, predictions))
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING ABOVE MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**Load the save model weight:**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on MC2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON MR2C DATASETS**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TESTING ON ME2C DATASETS**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Randomized to Canonical (MR2C) BART Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the canonicalized SMILES sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BART for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train, validation, and test sets
train_size = int(0.7 * len(dataset))  # 70% of the data for training
validation_size = int(0.15 * len(dataset))  # 15% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATIONS**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Define train_losses and train_accuracies
train_losses = []
train_accuracies = []

# Training loop
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(3):
    model.train()
    epoch_loss = 0
    correct = 0
    total = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        epoch_loss += loss.item()
        _, predicted = outputs.logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    # Calculate training loss and accuracy for the epoch
    epoch_loss /= len(train_loader)
    epoch_accuracy = correct / total

    # Append epoch loss and accuracy to the lists
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_accuracy)

    print(f'Epoch [{epoch + 1}/3], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, 4), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, 4), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Evaluation loop to get predictions and true labels
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()
predictions = np.argmax(logits_array, axis=1)
probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()

# Metrics calculations
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, probs[:, 1])
print("Accuracy:", accuracy)
print("AUROC:", auroc)
print("Classification Report:")
print(classification_report(true_labels, predictions))
mcc = matthews_corrcoef(true_labels, predictions)
print("MCC:", mcc)

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**Loading Above Model Weights**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on MR2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on MC2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Testing on ME2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**Masked Enumerated to Canonical (ME2C) BART Model**"""

import pandas as pd
import numpy as np
import torch
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef

# Load the dataset with canonicalized SMILES after R2C transformation
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the canonicalized SMILES sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = SMILESDataset(encodings, labels)

# Fine-tune BART for sequence classification
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset))

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Model training details with adjusted hyperparameters
batch_size = 64  # Decreased batch size
learning_rate = 2e-5  # Decreased learning rate
dropout = 0.3  # Increased dropout rate
initialization = "Xavier"
optimizer_used = "AdamW"
scheduler_used = "Linear"
frozen_encoder = "No"  # Assuming the encoder is not frozen
max_sequence_length = tokenizer.model_max_length
token_space = tokenizer.vocab_size
embedding_dimension = model.config.hidden_size
weight_decay = 0.01  # Define weight decay

# Data breakdown
size_training = int(0.8 * len(dataset))  # 80% of the dataset for training
size_validation = int(0.1 * len(dataset))  # 10% of the dataset for validation
size_test = len(dataset) - size_training - size_validation  # Remaining for testing

# Output model training details and data breakdown
print("Model training details:")
print("Training")
print("Parameter\tPre-training\tTransfer learning")
print(f"Batch size:\t{batch_size}")
print(f"Learning rate:\t{learning_rate}")
print(f"Weight decay:\t{weight_decay}")  # Fixed the variable name
print(f"Dropout:\t{dropout}")
print(f"Initialization:\t{initialization}\t{initialization}")
print(f"Optimizer:\t{optimizer_used}\t{optimizer_used}")
print(f"Scheduler:\t{scheduler_used}\t{scheduler_used}")
print(f"Frozen encoder:\t{frozen_encoder}\t{frozen_encoder}")
print(f"Max sequence length:\t{max_sequence_length}")
print(f"Token space:\t{token_space}")
print(f"Embedding dimension:\t{embedding_dimension}")

print("Data breakdown:")
print("Size Training:", size_training)
print("Size Validation:", size_validation)
print("Size Test:", size_test)

# Split data into train, validation, and test sets
train_size = int(0.8 * len(dataset))  # 80% of the data for training
validation_size = int(0.1 * len(dataset))  # 10% of the data for validation
test_size = len(dataset) - train_size - validation_size  # Remaining data for testing

train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])

# Training loop with adjusted hyperparameters
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)

for epoch in range(5):  # Increased training epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        if 'labels' in batch:
            labels = batch['labels'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            scheduler.step()

# Evaluation with adjusted hyperparameters
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

"""**VISUALIZATIONS**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Assuming train_losses and train_accuracies are lists containing losses and accuracies per epoch

# Visualize data breakdown
sizes = [size_training, size_validation, size_test]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART_Model"

# Save the model weights
model.save_pretrained(save_path)

# Save the tokenizer as well
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

"""**LOADING MODEL WEIGHTS**"""

from transformers import BartTokenizer, BartForSequenceClassification

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART_Model"

# Load the saved model and tokenizer
model = BartForSequenceClassification.from_pretrained(save_path)
tokenizer = BartTokenizer.from_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer loaded successfully from:", save_path)

"""**Test on ME2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MC2C DATASETS**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**TEST ON MR2C DATASETS**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve, roc_curve

import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Initialize BART tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings.input_ids)

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label='ROC curve')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()

"""**EWC PART START FROM HERE**

**1) BART + EWC on UNMASKED DATASETS**

**BART + EWC On C2C Datasets**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/C2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BART + EWC On R2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**SAVING MODEL WEIGHTS**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading model weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/R2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BART + EWC on E2C Datasets**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on E2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on C2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on R2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/E2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter UM R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**2) BART + EWC on MASKED DATASETS**

**BART + EWC on MC2C DATASETS**
"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MC2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BART + EWC on MR2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/MR2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**BART + EWC on ME2C DATASETS**"""

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from transformers import BartTokenizer, BartForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve

# Load the dataset with Canonical_SMILES
data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(data_path)

# Convert labels to tensors
labels = df['Label'].tolist()

# Split the data into train, validation, and test sets
train_smiles, test_smiles, train_labels, test_labels = train_test_split(df['Canonical_SMILES'], labels, test_size=0.1, random_state=42)
train_smiles, val_smiles, train_labels, val_labels = train_test_split(train_smiles, train_labels, test_size=0.1, random_state=42)

# Tokenize the Canonical_SMILES sequences
tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')
train_encodings = tokenizer(train_smiles.tolist(), truncation=True, padding=True)
val_encodings = tokenizer(val_smiles.tolist(), truncation=True, padding=True)
test_encodings = tokenizer(test_smiles.tolist(), truncation=True, padding=True)

# Convert labels to tensors
train_labels = torch.tensor(train_labels)
val_labels = torch.tensor(val_labels)
test_labels = torch.tensor(test_labels)

# Create PyTorch datasets
class SMILESDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SMILESDataset(train_encodings, train_labels)
val_dataset = SMILESDataset(val_encodings, val_labels)
test_dataset = SMILESDataset(test_encodings, test_labels)

# Define BART model architecture
model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=2)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset))

# Model training details
model_training_details = {
    "Batch size": 8,
    "Learning rate": 5e-5,
    "Weight decay": 0.01,
    "Dropout": 0.1,
    "Initialization": "Xavier",
    "Optimizer": "AdamW",
    "Scheduler": "Linear",
    "Frozen encoder": "No",
    "Max sequence length": tokenizer.model_max_length,
    "Token space": tokenizer.vocab_size,
    "Embedding dimension": model.config.hidden_size
}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define EWC parameters
fisher_dict = {}
optpar_dict = {}

# Calculate Fisher Information Matrix
def calculate_fisher(model, train_loader, fisher_dict, optpar_dict):
    model.train()
    for name, param in model.named_parameters():
        optpar_dict[name] = param.data.clone()
        fisher_dict[name] = torch.zeros_like(param.data)

    criterion = torch.nn.CrossEntropyLoss()

    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask)
        loss = criterion(outputs.logits, labels)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher_dict[name] += param.grad.data ** 2 / len(train_loader)

    return fisher_dict, optpar_dict

# EWC loss function
def ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc):
    loss = 0
    for name, param in model.named_parameters():
        if name in fisher_dict:
            loss += (fisher_dict[name] * (param - optpar_dict[name]) ** 2).sum()
    return lambda_ewc * loss

# Calculate Fisher Information Matrix
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
fisher_dict, optpar_dict = calculate_fisher(model, train_loader, fisher_dict, optpar_dict)

# Training loop
train_losses = []
train_accuracies = []

for epoch in range(3):
    model.train()
    total_loss = 0
    correct_predictions = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        ewc = ewc_loss(model, fisher_dict, optpar_dict, lambda_ewc=0.1)  # EWC hyperparameter lambda_ewc = 0.1
        total_loss += loss.item() + ewc.item()
        loss += ewc
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        correct_predictions += torch.sum(predictions == labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
    avg_loss = total_loss / len(train_loader)
    avg_accuracy = correct_predictions.double() / len(train_dataset)
    train_losses.append(avg_loss)
    train_accuracies.append(avg_accuracy.item())
    print(f"Epoch {epoch + 1}/{3}, Loss: {avg_loss}, Accuracy: {avg_accuracy}")

# Evaluation
model.eval()
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    true_labels.extend(labels.cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics
predictions = np.argmax(logits_array, axis=1)
accuracy = accuracy_score(true_labels, predictions)
auroc = roc_auc_score(true_labels, F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()[:, 1])
mcc = matthews_corrcoef(true_labels, predictions)

print("\nModel training details:")
for key, value in model_training_details.items():
    print(f"{key}:\t{value}")

print("\nData breakdown:")
print("Size\tTraining\tValidation\tTest")
print(f"{len(train_dataset)}\t{len(val_dataset)}\t{len(test_dataset)}")

print("\nEvaluation metrics:")
print(f"Accuracy: {accuracy}")
print(f"AUROC: {auroc}")
print(f"MCC: {mcc}")

print("\nClassification Report:")
print(classification_report(true_labels, predictions))

# Visualizations

# Visualize data breakdown
sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]
labels = ['Training', 'Validation', 'Test']
plt.figure(figsize=(8, 6))
plt.bar(labels, sizes, color=['blue', 'orange', 'green'])
plt.xlabel('Data Split')
plt.ylabel('Size')
plt.title('Data Breakdown')
plt.show()

# Visualize training loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Value')
plt.title('Training Loss and Accuracy')
plt.legend()
plt.show()

# Visualize confusion matrix
cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Visualize ROC curve
probs = F.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f)' % auroc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Visualize precision-recall curve
precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**Saving Model Weights**"""

import pickle
import torch

# Define the path to save the model
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART+EWC_Model"

# Save the model weights and tokenizer
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

# Print confirmation message
print("Model and tokenizer saved successfully at:", save_path)

# Save EWC-related data
ewc_data = {
    'fisher_dict': fisher_dict,
    'optpar_dict': optpar_dict
}

# Save EWC data
with open(f"{save_path}/ewc_data.pkl", 'wb') as f:
    pickle.dump(ewc_data, f)

print("EWC data saved successfully at:", save_path)

"""**Loading Model Weights**"""

import pickle
import torch
from transformers import BartForSequenceClassification, BartTokenizer

# Define the path where the model is saved
save_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART+EWC_Model"

# Load the model and tokenizer
loaded_model = BartForSequenceClassification.from_pretrained(save_path)
loaded_tokenizer = BartTokenizer.from_pretrained(save_path)

# Load EWC data
with open(f"{save_path}/ewc_data.pkl", 'rb') as f:
    ewc_data = pickle.load(f)

fisher_dict = ewc_data['fisher_dict']
optpar_dict = ewc_data['optpar_dict']

# Print confirmation message
print("Model, tokenizer, and EWC data loaded successfully.")

"""**Test on ME2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M E2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MC2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M C2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")

"""**Test on MR2C Datasets**"""

import torch
from transformers import BartTokenizer, BartForSequenceClassification
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef, confusion_matrix, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved BART model
saved_model_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Saved Model/ME2C_BART+EWC_Model"
model = BartForSequenceClassification.from_pretrained(saved_model_path)
tokenizer = BartTokenizer.from_pretrained(saved_model_path)

# Load the new dataset
new_data_path = "/content/drive/MyDrive/Data for IIT BHU/New XAI Datasets/Bitter M R2C.csv"
df = pd.read_csv(new_data_path)

# Tokenize the sequences
encodings = tokenizer(df['Canonical_SMILES'].tolist(), truncation=True, padding=True)

# Convert labels to tensors if available
if 'Label' in df.columns:
    labels = torch.tensor(df['Label'].tolist())
else:
    labels = None

# Create PyTorch dataset
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

dataset = CustomDataset(encodings, labels)

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Test the model on the new dataset
model.eval()
loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)

logits_list = []
true_labels = []

for batch in loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    logits_list.append(logits)
    if 'labels' in batch:
        true_labels.extend(batch['labels'].cpu().numpy())

# Concatenate logits from all batches
logits_array = torch.cat(logits_list).cpu().numpy()

# Calculate metrics if labels are available
if labels is not None:
    predictions = np.argmax(logits_array, axis=1)
    accuracy = accuracy_score(true_labels, predictions)
    print("Accuracy:", accuracy)

    probs = torch.softmax(torch.tensor(logits_array), dim=1).cpu().numpy()
    auroc = roc_auc_score(true_labels, probs[:, 1])
    print("AUROC:", auroc)

    print("Classification Report:")
    print(classification_report(true_labels, predictions))

    mcc = matthews_corrcoef(true_labels, predictions)
    print("MCC:", mcc)

    # Plot the confusion matrix
    cm = confusion_matrix(true_labels, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()

    # Plot the ROC curve
    fpr, tpr, thresholds = roc_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {auroc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot the precision-recall curve
    precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='green', label='Precision-Recall curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

    # Plot the histogram of predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.hist(probs[:, 1], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    plt.xlabel('Predicted Probability')
    plt.ylabel('Frequency')
    plt.title('Histogram of Predicted Probabilities')
    plt.show()
else:
    print("No labels provided in the new dataset. Metrics will not be calculated.")