==========================================
SLURM_CLUSTER_NAME = param-shivay
SLURM_JOB_ACCOUNT = comp_sci_engg
SLURM_JOB_ID = 980908
SLURM_JOB_NAME = xai_3
SLURM_JOB_NODELIST = gpu[004-005]
SLURM_JOB_USER = sakshi.rs.cse21.itbhu
SLURM_JOB_UID = 6147
SLURM_JOB_PARTITION = gpu
SLURM_TASK_PID = 39410
SLURM_SUBMIT_DIR = /home/sakshi.rs.cse21.itbhu
SLURM_CPUS_ON_NODE = 10
SLURM_NTASKS = 20
SLURM_TASK_PID = 39410
==========================================
{'loss': 0.5661, 'grad_norm': 14.971887588500977, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}
{'loss': 0.4544, 'grad_norm': 4.7956953048706055, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}
{'loss': 0.3542, 'grad_norm': 8.745563507080078, 'learning_rate': 3e-06, 'epoch': 0.13}
{'loss': 0.3952, 'grad_norm': 9.072469711303711, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.17}
{'loss': 0.3931, 'grad_norm': 17.03316879272461, 'learning_rate': 5e-06, 'epoch': 0.22}
{'loss': 0.3693, 'grad_norm': 15.477259635925293, 'learning_rate': 6e-06, 'epoch': 0.26}
{'loss': 0.5379, 'grad_norm': 25.490768432617188, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.3}
{'loss': 0.4178, 'grad_norm': 9.793821334838867, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.35}
{'loss': 0.341, 'grad_norm': 14.947690963745117, 'learning_rate': 9e-06, 'epoch': 0.39}
{'loss': 0.3443, 'grad_norm': 22.666954040527344, 'learning_rate': 1e-05, 'epoch': 0.43}
{'loss': 0.537, 'grad_norm': 8.11522388458252, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.48}
{'loss': 0.413, 'grad_norm': 19.290733337402344, 'learning_rate': 1.2e-05, 'epoch': 0.52}
{'loss': 0.4208, 'grad_norm': 7.12064266204834, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.57}
{'loss': 0.6102, 'grad_norm': 20.726306915283203, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.61}
{'loss': 0.4958, 'grad_norm': 7.495433807373047, 'learning_rate': 1.5e-05, 'epoch': 0.65}
{'loss': 0.4564, 'grad_norm': 4.485565662384033, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.7}
{'loss': 0.4307, 'grad_norm': 4.340393543243408, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.74}
{'loss': 0.4146, 'grad_norm': 14.833257675170898, 'learning_rate': 1.8e-05, 'epoch': 0.78}
{'loss': 0.4587, 'grad_norm': 7.227773666381836, 'learning_rate': 1.9e-05, 'epoch': 0.83}
{'loss': 0.3641, 'grad_norm': 21.340137481689453, 'learning_rate': 2e-05, 'epoch': 0.87}
{'loss': 0.3657, 'grad_norm': 42.99437713623047, 'learning_rate': 2.1e-05, 'epoch': 0.91}
{'loss': 0.3243, 'grad_norm': 12.1327543258667, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.96}
{'loss': 0.5718, 'grad_norm': 2.9061317443847656, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.0}
{'eval_loss': 0.3909960091114044, 'eval_runtime': 31.0573, 'eval_samples_per_second': 6.569, 'eval_steps_per_second': 0.837, 'epoch': 1.0}
{'loss': 0.3657, 'grad_norm': 21.7662410736084, 'learning_rate': 2.4e-05, 'epoch': 1.04}
{'loss': 0.3668, 'grad_norm': 21.125701904296875, 'learning_rate': 2.5e-05, 'epoch': 1.09}
{'loss': 0.3729, 'grad_norm': 3.4051992893218994, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.13}
{'loss': 0.4528, 'grad_norm': 3.0689821243286133, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.17}
{'loss': 0.3236, 'grad_norm': 15.759896278381348, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.22}
{'loss': 0.359, 'grad_norm': 3.279592990875244, 'learning_rate': 2.9e-05, 'epoch': 1.26}
{'loss': 0.4805, 'grad_norm': 5.784442901611328, 'learning_rate': 3e-05, 'epoch': 1.3}
{'loss': 0.5546, 'grad_norm': 7.724681377410889, 'learning_rate': 3.1e-05, 'epoch': 1.35}
{'loss': 0.3532, 'grad_norm': 3.377434492111206, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.39}
{'loss': 0.4032, 'grad_norm': 11.814345359802246, 'learning_rate': 3.3e-05, 'epoch': 1.43}
{'loss': 0.3829, 'grad_norm': 9.68991756439209, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.48}
{'loss': 0.4431, 'grad_norm': 2.2910358905792236, 'learning_rate': 3.5e-05, 'epoch': 1.52}
{'loss': 0.5681, 'grad_norm': 42.48578643798828, 'learning_rate': 3.6e-05, 'epoch': 1.57}
{'loss': 0.5037, 'grad_norm': 19.187332153320312, 'learning_rate': 3.7e-05, 'epoch': 1.61}
{'loss': 0.5528, 'grad_norm': 2.9016425609588623, 'learning_rate': 3.8e-05, 'epoch': 1.65}
{'loss': 0.4678, 'grad_norm': 5.830329418182373, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.7}
{'loss': 0.3588, 'grad_norm': 8.838534355163574, 'learning_rate': 4e-05, 'epoch': 1.74}
{'loss': 0.4634, 'grad_norm': 5.9331278800964355, 'learning_rate': 4.1e-05, 'epoch': 1.78}
{'loss': 0.4201, 'grad_norm': 5.745471954345703, 'learning_rate': 4.2e-05, 'epoch': 1.83}
{'loss': 0.426, 'grad_norm': 4.6393890380859375, 'learning_rate': 4.3e-05, 'epoch': 1.87}
{'loss': 0.5255, 'grad_norm': 1.2684606313705444, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.91}
{'loss': 0.6614, 'grad_norm': 3.2891626358032227, 'learning_rate': 4.5e-05, 'epoch': 1.96}
{'loss': 0.3878, 'grad_norm': 10.715027809143066, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.0}
{'eval_loss': 0.4040466845035553, 'eval_runtime': 14.0933, 'eval_samples_per_second': 14.475, 'eval_steps_per_second': 1.845, 'epoch': 2.0}
{'loss': 0.2933, 'grad_norm': 2.6990270614624023, 'learning_rate': 4.7e-05, 'epoch': 2.04}
{'loss': 0.3294, 'grad_norm': 5.9983391761779785, 'learning_rate': 4.8e-05, 'epoch': 2.09}
{'loss': 0.4325, 'grad_norm': 17.655895233154297, 'learning_rate': 4.9e-05, 'epoch': 2.13}
{'loss': 0.5826, 'grad_norm': 5.8328776359558105, 'learning_rate': 5e-05, 'epoch': 2.17}
{'loss': 0.3741, 'grad_norm': 3.336772918701172, 'learning_rate': 4.736842105263158e-05, 'epoch': 2.22}
{'loss': 0.4745, 'grad_norm': 5.928300857543945, 'learning_rate': 4.473684210526316e-05, 'epoch': 2.26}
{'loss': 0.458, 'grad_norm': 6.7220988273620605, 'learning_rate': 4.210526315789474e-05, 'epoch': 2.3}
{'loss': 0.3533, 'grad_norm': 2.542945146560669, 'learning_rate': 3.9473684210526316e-05, 'epoch': 2.35}
{'loss': 0.432, 'grad_norm': 10.003220558166504, 'learning_rate': 3.6842105263157895e-05, 'epoch': 2.39}
{'loss': 0.4407, 'grad_norm': 5.891584396362305, 'learning_rate': 3.421052631578947e-05, 'epoch': 2.43}
{'loss': 0.4374, 'grad_norm': 4.3721723556518555, 'learning_rate': 3.157894736842105e-05, 'epoch': 2.48}
{'loss': 0.5283, 'grad_norm': 11.408356666564941, 'learning_rate': 2.8947368421052634e-05, 'epoch': 2.52}
{'loss': 0.4334, 'grad_norm': 3.5132761001586914, 'learning_rate': 2.6315789473684212e-05, 'epoch': 2.57}
{'loss': 0.4445, 'grad_norm': 3.559251546859741, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.61}
{'loss': 0.3405, 'grad_norm': 13.37053394317627, 'learning_rate': 2.105263157894737e-05, 'epoch': 2.65}
{'loss': 0.398, 'grad_norm': 7.573024272918701, 'learning_rate': 1.8421052631578947e-05, 'epoch': 2.7}
{'loss': 0.4032, 'grad_norm': 1.9624601602554321, 'learning_rate': 1.5789473684210526e-05, 'epoch': 2.74}
{'loss': 0.3103, 'grad_norm': 10.108513832092285, 'learning_rate': 1.3157894736842106e-05, 'epoch': 2.78}
{'loss': 0.3708, 'grad_norm': 5.965550422668457, 'learning_rate': 1.0526315789473684e-05, 'epoch': 2.83}
{'loss': 0.474, 'grad_norm': 7.632904052734375, 'learning_rate': 7.894736842105263e-06, 'epoch': 2.87}
{'loss': 0.2987, 'grad_norm': 7.241562843322754, 'learning_rate': 5.263157894736842e-06, 'epoch': 2.91}
{'loss': 0.5446, 'grad_norm': 17.406658172607422, 'learning_rate': 2.631578947368421e-06, 'epoch': 2.96}
{'loss': 0.3561, 'grad_norm': 5.908738136291504, 'learning_rate': 0.0, 'epoch': 3.0}
{'eval_loss': 0.37628141045570374, 'eval_runtime': 34.9211, 'eval_samples_per_second': 5.842, 'eval_steps_per_second': 0.745, 'epoch': 3.0}
{'train_runtime': 6156.6231, 'train_samples_per_second': 0.894, 'train_steps_per_second': 0.112, 'train_loss': 0.43101831933726437, 'epoch': 3.0}
Attention maps saved to /scratch/sakshi.rs.cse21.itbhu/dheeraj/XAI/XAI1/All_XAI_Computed/C2C_Attention_Maps.csv successfully.
An error occurred during training or attention map computation: only one element tensors can be converted to Python scalars
Computation or saving of attention maps failed.
