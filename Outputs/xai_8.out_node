==========================================
SLURM_CLUSTER_NAME = param-shivay
SLURM_JOB_ACCOUNT = comp_sci_engg
SLURM_JOB_ID = 981037
SLURM_JOB_NAME = xai_8
SLURM_JOB_NODELIST = gpu[004-005]
SLURM_JOB_USER = sakshi.rs.cse21.itbhu
SLURM_JOB_UID = 6147
SLURM_JOB_PARTITION = gpu
SLURM_TASK_PID = 61787
SLURM_SUBMIT_DIR = /home/sakshi.rs.cse21.itbhu
SLURM_CPUS_ON_NODE = 10
SLURM_NTASKS = 20
SLURM_TASK_PID = 61787
==========================================
{'loss': 0.3972, 'grad_norm': 4.6444525718688965, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}
{'loss': 0.5482, 'grad_norm': 7.189823150634766, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}
{'loss': 0.4446, 'grad_norm': 6.433811187744141, 'learning_rate': 3e-06, 'epoch': 0.13}
{'loss': 0.2809, 'grad_norm': 49.86256408691406, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.17}
{'loss': 0.4389, 'grad_norm': 12.842733383178711, 'learning_rate': 5e-06, 'epoch': 0.22}
{'loss': 0.3306, 'grad_norm': 35.0508918762207, 'learning_rate': 6e-06, 'epoch': 0.26}
{'loss': 0.3661, 'grad_norm': 20.100955963134766, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.3}
{'loss': 0.3244, 'grad_norm': 9.877229690551758, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.35}
{'loss': 0.5624, 'grad_norm': 10.687994956970215, 'learning_rate': 9e-06, 'epoch': 0.39}
{'loss': 0.3349, 'grad_norm': 17.10740089416504, 'learning_rate': 1e-05, 'epoch': 0.43}
{'loss': 0.4493, 'grad_norm': 4.465103626251221, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.48}
{'loss': 0.606, 'grad_norm': 12.945291519165039, 'learning_rate': 1.2e-05, 'epoch': 0.52}
{'loss': 0.3293, 'grad_norm': 2.904489755630493, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.57}
{'loss': 0.2849, 'grad_norm': 9.977086067199707, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.61}
{'loss': 0.4877, 'grad_norm': 21.198331832885742, 'learning_rate': 1.5e-05, 'epoch': 0.65}
{'loss': 0.4504, 'grad_norm': 8.340622901916504, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.7}
{'loss': 0.4921, 'grad_norm': 9.073318481445312, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.74}
{'loss': 0.4797, 'grad_norm': 4.1857099533081055, 'learning_rate': 1.8e-05, 'epoch': 0.78}
{'loss': 0.6021, 'grad_norm': 6.197108268737793, 'learning_rate': 1.9e-05, 'epoch': 0.83}
{'loss': 0.4567, 'grad_norm': 5.042494297027588, 'learning_rate': 2e-05, 'epoch': 0.87}
{'loss': 0.4711, 'grad_norm': 9.830631256103516, 'learning_rate': 2.1e-05, 'epoch': 0.91}
{'loss': 0.4008, 'grad_norm': 4.103034019470215, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.96}
{'loss': 0.7202, 'grad_norm': 10.558374404907227, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.0}
{'eval_loss': 0.5170647501945496, 'eval_runtime': 4.1221, 'eval_samples_per_second': 49.489, 'eval_steps_per_second': 6.307, 'epoch': 1.0}
{'loss': 0.5824, 'grad_norm': 5.507317066192627, 'learning_rate': 2.4e-05, 'epoch': 1.04}
{'loss': 0.4615, 'grad_norm': 4.16527795791626, 'learning_rate': 2.5e-05, 'epoch': 1.09}
{'loss': 0.3158, 'grad_norm': 9.148984909057617, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.13}
{'loss': 0.4493, 'grad_norm': 16.645906448364258, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.17}
{'loss': 0.464, 'grad_norm': 2.9654574394226074, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.22}
{'loss': 0.5094, 'grad_norm': 17.730670928955078, 'learning_rate': 2.9e-05, 'epoch': 1.26}
{'loss': 0.6138, 'grad_norm': 39.82748794555664, 'learning_rate': 3e-05, 'epoch': 1.3}
{'loss': 0.5942, 'grad_norm': 6.35479211807251, 'learning_rate': 3.1e-05, 'epoch': 1.35}
{'loss': 0.4452, 'grad_norm': 16.358478546142578, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.39}
{'loss': 0.2443, 'grad_norm': 2.6426804065704346, 'learning_rate': 3.3e-05, 'epoch': 1.43}
{'loss': 0.4562, 'grad_norm': 9.032163619995117, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.48}
{'loss': 0.4417, 'grad_norm': 13.693831443786621, 'learning_rate': 3.5e-05, 'epoch': 1.52}
{'loss': 0.511, 'grad_norm': 11.849190711975098, 'learning_rate': 3.6e-05, 'epoch': 1.57}
{'loss': 0.5327, 'grad_norm': 29.44569969177246, 'learning_rate': 3.7e-05, 'epoch': 1.61}
{'loss': 0.5082, 'grad_norm': 9.966571807861328, 'learning_rate': 3.8e-05, 'epoch': 1.65}
{'loss': 0.4695, 'grad_norm': 7.401885986328125, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.7}
{'loss': 0.3389, 'grad_norm': 2.4331164360046387, 'learning_rate': 4e-05, 'epoch': 1.74}
{'loss': 0.5934, 'grad_norm': 14.542724609375, 'learning_rate': 4.1e-05, 'epoch': 1.78}
{'loss': 0.5973, 'grad_norm': 10.503053665161133, 'learning_rate': 4.2e-05, 'epoch': 1.83}
{'loss': 0.4032, 'grad_norm': 5.313509941101074, 'learning_rate': 4.3e-05, 'epoch': 1.87}
{'loss': 0.4478, 'grad_norm': 13.133594512939453, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.91}
{'loss': 0.5114, 'grad_norm': 6.061751365661621, 'learning_rate': 4.5e-05, 'epoch': 1.96}
{'loss': 0.4043, 'grad_norm': 2.3479435443878174, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.0}
{'eval_loss': 0.40117937326431274, 'eval_runtime': 3.8994, 'eval_samples_per_second': 52.316, 'eval_steps_per_second': 6.668, 'epoch': 2.0}
{'loss': 0.598, 'grad_norm': 8.926797866821289, 'learning_rate': 4.7e-05, 'epoch': 2.04}
{'loss': 0.4209, 'grad_norm': 6.936924934387207, 'learning_rate': 4.8e-05, 'epoch': 2.09}
{'loss': 0.3714, 'grad_norm': 7.165186405181885, 'learning_rate': 4.9e-05, 'epoch': 2.13}
{'loss': 0.5267, 'grad_norm': 5.539752006530762, 'learning_rate': 5e-05, 'epoch': 2.17}
{'loss': 0.4582, 'grad_norm': 15.699247360229492, 'learning_rate': 4.736842105263158e-05, 'epoch': 2.22}
{'loss': 0.427, 'grad_norm': 10.086498260498047, 'learning_rate': 4.473684210526316e-05, 'epoch': 2.26}
{'loss': 0.3049, 'grad_norm': 3.4206128120422363, 'learning_rate': 4.210526315789474e-05, 'epoch': 2.3}
{'loss': 0.5186, 'grad_norm': 9.257627487182617, 'learning_rate': 3.9473684210526316e-05, 'epoch': 2.35}
{'loss': 0.3856, 'grad_norm': 27.824901580810547, 'learning_rate': 3.6842105263157895e-05, 'epoch': 2.39}
{'loss': 0.4431, 'grad_norm': 3.715664863586426, 'learning_rate': 3.421052631578947e-05, 'epoch': 2.43}
{'loss': 0.4429, 'grad_norm': 12.222192764282227, 'learning_rate': 3.157894736842105e-05, 'epoch': 2.48}
{'loss': 0.3367, 'grad_norm': 4.132478713989258, 'learning_rate': 2.8947368421052634e-05, 'epoch': 2.52}
{'loss': 0.3184, 'grad_norm': 15.124497413635254, 'learning_rate': 2.6315789473684212e-05, 'epoch': 2.57}
{'loss': 0.3699, 'grad_norm': 4.641750812530518, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.61}
{'loss': 0.5579, 'grad_norm': 7.621746063232422, 'learning_rate': 2.105263157894737e-05, 'epoch': 2.65}
{'loss': 0.5694, 'grad_norm': 10.539337158203125, 'learning_rate': 1.8421052631578947e-05, 'epoch': 2.7}
{'loss': 0.3573, 'grad_norm': 3.979649066925049, 'learning_rate': 1.5789473684210526e-05, 'epoch': 2.74}
{'loss': 0.3196, 'grad_norm': 8.993749618530273, 'learning_rate': 1.3157894736842106e-05, 'epoch': 2.78}
{'loss': 0.292, 'grad_norm': 4.9150543212890625, 'learning_rate': 1.0526315789473684e-05, 'epoch': 2.83}
{'loss': 0.2861, 'grad_norm': 10.34419059753418, 'learning_rate': 7.894736842105263e-06, 'epoch': 2.87}
{'loss': 0.4532, 'grad_norm': 10.45040225982666, 'learning_rate': 5.263157894736842e-06, 'epoch': 2.91}
{'loss': 0.317, 'grad_norm': 4.149197578430176, 'learning_rate': 2.631578947368421e-06, 'epoch': 2.96}
{'loss': 0.5607, 'grad_norm': 28.98661231994629, 'learning_rate': 0.0, 'epoch': 3.0}
{'eval_loss': 0.37627649307250977, 'eval_runtime': 3.9455, 'eval_samples_per_second': 51.704, 'eval_steps_per_second': 6.59, 'epoch': 3.0}
{'train_runtime': 634.9464, 'train_samples_per_second': 8.67, 'train_steps_per_second': 1.087, 'train_loss': 0.4462225979652958, 'epoch': 3.0}
Attention map dimensions: [torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50]), torch.Size([2039, 12, 50, 50])]
Logits dimensions before reshape: torch.Size([2039, 2])
Logits dimensions after expansion: torch.Size([2039, 12, 2, 50])
Attention-weighted Contextual Attention maps saved to /scratch/sakshi.rs.cse21.itbhu/dheeraj/XAI/XAI1/All_XAI_Computed/C2C_AttCAT_Maps.csv successfully.
An error occurred during training or Attention-weighted Contextual Attention map computation: only one element tensors can be converted to Python scalars
