==========================================
SLURM_CLUSTER_NAME = param-shivay
SLURM_JOB_ACCOUNT = comp_sci_engg
SLURM_JOB_ID = 981023
SLURM_JOB_NAME = xai_7
SLURM_JOB_NODELIST = gpu[004-005]
SLURM_JOB_USER = sakshi.rs.cse21.itbhu
SLURM_JOB_UID = 6147
SLURM_JOB_PARTITION = gpu
SLURM_TASK_PID = 55123
SLURM_SUBMIT_DIR = /home/sakshi.rs.cse21.itbhu
SLURM_CPUS_ON_NODE = 10
SLURM_NTASKS = 20
SLURM_TASK_PID = 55123
==========================================
{'loss': 0.5587, 'grad_norm': 9.731135368347168, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}
{'loss': 0.555, 'grad_norm': 14.761985778808594, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}
{'loss': 0.454, 'grad_norm': 5.571545124053955, 'learning_rate': 3e-06, 'epoch': 0.13}
{'loss': 0.3891, 'grad_norm': 11.12409782409668, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.17}
{'loss': 0.3964, 'grad_norm': 10.571222305297852, 'learning_rate': 5e-06, 'epoch': 0.22}
{'loss': 0.2868, 'grad_norm': 12.136228561401367, 'learning_rate': 6e-06, 'epoch': 0.26}
{'loss': 0.5612, 'grad_norm': 8.446917533874512, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.3}
{'loss': 0.464, 'grad_norm': 14.112320899963379, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.35}
{'loss': 0.471, 'grad_norm': 23.348125457763672, 'learning_rate': 9e-06, 'epoch': 0.39}
{'loss': 0.3659, 'grad_norm': 13.029328346252441, 'learning_rate': 1e-05, 'epoch': 0.43}
{'loss': 0.3806, 'grad_norm': 14.324604988098145, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.48}
{'loss': 0.441, 'grad_norm': 168.039306640625, 'learning_rate': 1.2e-05, 'epoch': 0.52}
{'loss': 0.3315, 'grad_norm': 6.257669448852539, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.57}
{'loss': 0.4389, 'grad_norm': 2.934173107147217, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.61}
{'loss': 0.3856, 'grad_norm': 13.133472442626953, 'learning_rate': 1.5e-05, 'epoch': 0.65}
{'loss': 0.4115, 'grad_norm': 3.5837273597717285, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.7}
{'loss': 0.3948, 'grad_norm': 3.7008371353149414, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.74}
{'loss': 0.4209, 'grad_norm': 7.611828804016113, 'learning_rate': 1.8e-05, 'epoch': 0.78}
{'loss': 0.5576, 'grad_norm': 19.723621368408203, 'learning_rate': 1.9e-05, 'epoch': 0.83}
{'loss': 0.2914, 'grad_norm': 7.036025524139404, 'learning_rate': 2e-05, 'epoch': 0.87}
{'loss': 0.4102, 'grad_norm': 9.458720207214355, 'learning_rate': 2.1e-05, 'epoch': 0.91}
{'loss': 0.375, 'grad_norm': 2.9572336673736572, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.96}
{'loss': 0.586, 'grad_norm': 3.4389636516571045, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.0}
{'eval_loss': 0.47068989276885986, 'eval_runtime': 17.2683, 'eval_samples_per_second': 11.814, 'eval_steps_per_second': 1.506, 'epoch': 1.0}
{'loss': 0.3653, 'grad_norm': 5.09999942779541, 'learning_rate': 2.4e-05, 'epoch': 1.04}
{'loss': 0.3233, 'grad_norm': 12.977470397949219, 'learning_rate': 2.5e-05, 'epoch': 1.09}
{'loss': 0.3872, 'grad_norm': 13.140300750732422, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.13}
{'loss': 0.314, 'grad_norm': 5.935739517211914, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.17}
{'loss': 0.5783, 'grad_norm': 27.685529708862305, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.22}
{'loss': 0.3417, 'grad_norm': 4.3238844871521, 'learning_rate': 2.9e-05, 'epoch': 1.26}
{'loss': 0.5159, 'grad_norm': 10.645589828491211, 'learning_rate': 3e-05, 'epoch': 1.3}
{'loss': 0.4441, 'grad_norm': 9.964750289916992, 'learning_rate': 3.1e-05, 'epoch': 1.35}
{'loss': 0.4902, 'grad_norm': 17.269672393798828, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.39}
{'loss': 0.5328, 'grad_norm': 3.849602699279785, 'learning_rate': 3.3e-05, 'epoch': 1.43}
{'loss': 0.4314, 'grad_norm': 4.6396331787109375, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.48}
{'loss': 0.377, 'grad_norm': 3.956888198852539, 'learning_rate': 3.5e-05, 'epoch': 1.52}
{'loss': 0.5007, 'grad_norm': 23.110300064086914, 'learning_rate': 3.6e-05, 'epoch': 1.57}
{'loss': 0.4536, 'grad_norm': 9.779105186462402, 'learning_rate': 3.7e-05, 'epoch': 1.61}
{'loss': 0.4967, 'grad_norm': 4.152601718902588, 'learning_rate': 3.8e-05, 'epoch': 1.65}
{'loss': 0.4854, 'grad_norm': 14.036763191223145, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.7}
{'loss': 0.4478, 'grad_norm': 3.0430095195770264, 'learning_rate': 4e-05, 'epoch': 1.74}
{'loss': 0.4693, 'grad_norm': 9.52977180480957, 'learning_rate': 4.1e-05, 'epoch': 1.78}
{'loss': 0.4107, 'grad_norm': 7.301566123962402, 'learning_rate': 4.2e-05, 'epoch': 1.83}
{'loss': 0.556, 'grad_norm': 53.64155960083008, 'learning_rate': 4.3e-05, 'epoch': 1.87}
{'loss': 0.5185, 'grad_norm': 5.685880184173584, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.91}
{'loss': 0.4621, 'grad_norm': 3.23051381111145, 'learning_rate': 4.5e-05, 'epoch': 1.96}
{'loss': 0.4638, 'grad_norm': 13.477886199951172, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.0}
{'eval_loss': 0.5549831986427307, 'eval_runtime': 4.0169, 'eval_samples_per_second': 50.786, 'eval_steps_per_second': 6.473, 'epoch': 2.0}
{'loss': 0.4253, 'grad_norm': 20.799644470214844, 'learning_rate': 4.7e-05, 'epoch': 2.04}
{'loss': 0.4734, 'grad_norm': 16.41427230834961, 'learning_rate': 4.8e-05, 'epoch': 2.09}
{'loss': 0.3949, 'grad_norm': 7.750630855560303, 'learning_rate': 4.9e-05, 'epoch': 2.13}
{'loss': 0.5164, 'grad_norm': 4.9133758544921875, 'learning_rate': 5e-05, 'epoch': 2.17}
{'loss': 0.4119, 'grad_norm': 6.070267677307129, 'learning_rate': 4.736842105263158e-05, 'epoch': 2.22}
{'loss': 0.5562, 'grad_norm': 3.403001308441162, 'learning_rate': 4.473684210526316e-05, 'epoch': 2.26}
{'loss': 0.3046, 'grad_norm': 5.534379959106445, 'learning_rate': 4.210526315789474e-05, 'epoch': 2.3}
{'loss': 0.4229, 'grad_norm': 7.300784587860107, 'learning_rate': 3.9473684210526316e-05, 'epoch': 2.35}
{'loss': 0.365, 'grad_norm': 43.485267639160156, 'learning_rate': 3.6842105263157895e-05, 'epoch': 2.39}
{'loss': 0.5218, 'grad_norm': 36.05868911743164, 'learning_rate': 3.421052631578947e-05, 'epoch': 2.43}
{'loss': 0.6147, 'grad_norm': 11.861977577209473, 'learning_rate': 3.157894736842105e-05, 'epoch': 2.48}
{'loss': 0.6601, 'grad_norm': 8.733860969543457, 'learning_rate': 2.8947368421052634e-05, 'epoch': 2.52}
{'loss': 0.5448, 'grad_norm': 5.3999810218811035, 'learning_rate': 2.6315789473684212e-05, 'epoch': 2.57}
{'loss': 0.4157, 'grad_norm': 5.184796333312988, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.61}
{'loss': 0.4172, 'grad_norm': 3.566575765609741, 'learning_rate': 2.105263157894737e-05, 'epoch': 2.65}
{'loss': 0.3346, 'grad_norm': 9.415315628051758, 'learning_rate': 1.8421052631578947e-05, 'epoch': 2.7}
{'loss': 0.39, 'grad_norm': 24.811559677124023, 'learning_rate': 1.5789473684210526e-05, 'epoch': 2.74}
{'loss': 0.5359, 'grad_norm': 9.381447792053223, 'learning_rate': 1.3157894736842106e-05, 'epoch': 2.78}
{'loss': 0.6068, 'grad_norm': 7.193089485168457, 'learning_rate': 1.0526315789473684e-05, 'epoch': 2.83}
{'loss': 0.4786, 'grad_norm': 8.66087818145752, 'learning_rate': 7.894736842105263e-06, 'epoch': 2.87}
{'loss': 0.3123, 'grad_norm': 4.705325126647949, 'learning_rate': 5.263157894736842e-06, 'epoch': 2.91}
{'loss': 0.3939, 'grad_norm': 7.348532676696777, 'learning_rate': 2.631578947368421e-06, 'epoch': 2.96}
{'loss': 0.4654, 'grad_norm': 17.755788803100586, 'learning_rate': 0.0, 'epoch': 3.0}
{'eval_loss': 0.4486127495765686, 'eval_runtime': 19.4956, 'eval_samples_per_second': 10.464, 'eval_steps_per_second': 1.334, 'epoch': 3.0}
{'train_runtime': 3216.4912, 'train_samples_per_second': 1.711, 'train_steps_per_second': 0.215, 'train_loss': 0.447182832247969, 'epoch': 3.0}
Contextual Attention maps saved to /scratch/sakshi.rs.cse21.itbhu/dheeraj/XAI/XAI1/All_XAI_Computed/C2C_CAT_Maps.csv successfully.
An error occurred during training or Contextual Attention map computation: only one element tensors can be converted to Python scalars
Computation or saving of Contextual Attention maps failed.
